{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import clear_output\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import requests\n",
    "# Specify the URL of the business page on Google Maps\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "engine = create_engine('postgresql://postgres:*Your_Database_Password*@localhost:5432/DIY')\n",
    "\n",
    "option = Options()\n",
    "option.add_argument(\"--disable-infobars\")\n",
    "option.add_argument(\"start-maximized\")\n",
    "option.add_argument(\"--disable-extensions\")\n",
    "# Keep Improving! the argument 1 to allow and 2 to block\n",
    "option.add_experimental_option(\n",
    "    \"prefs\", {\"profile.default_content_setting_values.notifications\": 1}\n",
    "    )\n",
    "driver = webdriver.Chrome(options=option, service=ChromeService())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_competitor_name = \"Miniso\" # Ganti seusai nama kompetitor\n",
    "conf_sql_name = \"Review_Maps_\" + conf_competitor_name\n",
    "conf_path_store_link = f\"S:\\\\Web Scrap\\\\Sentiment Analysist\\\\Scrapping GMaps Review\\\\Source Link Maps per Store\\\\{conf_competitor_name}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Link Gmaps</th>\n",
       "      <th>Region</th>\n",
       "      <th>Province</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Miniso Queen City Semarang</td>\n",
       "      <td>https://maps.app.goo.gl/rA4KY2X9cdUuKkMR9</td>\n",
       "      <td>Java Non Jabodetabek</td>\n",
       "      <td>Central Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Miniso Supermal Karawaci</td>\n",
       "      <td>https://maps.app.goo.gl/wqSj3v2aTWMregMc6</td>\n",
       "      <td>Jabodetabek</td>\n",
       "      <td>Banten</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Store Name                                 Link Gmaps  \\\n",
       "0  Miniso Queen City Semarang  https://maps.app.goo.gl/rA4KY2X9cdUuKkMR9   \n",
       "1    Miniso Supermal Karawaci  https://maps.app.goo.gl/wqSj3v2aTWMregMc6   \n",
       "\n",
       "                 Region      Province  \n",
       "0  Java Non Jabodetabek  Central Java  \n",
       "1           Jabodetabek        Banten  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store = pd.read_csv(conf_path_store_link)\n",
    "df_store = df_store[['Store Name','Link Gmaps','Region','Province']]\n",
    "df_store.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_review(comp_store_name,comp_region,comp_province):\n",
    "    temp = {\n",
    "        'reviewer_name':[],\n",
    "        'review':[],\n",
    "        'date':[],\n",
    "        'rating':[],\n",
    "    }\n",
    "    reviewer = driver.find_elements(By.XPATH, \"//div[contains(@class, 'jftiEf')]\")\n",
    "    for rev in reviewer:\n",
    "        try :\n",
    "            try :\n",
    "                press_others = rev.find_element(By.XPATH,'.//div[@class= \"MyEned\"]/span/button[@class=\"w8nwRe kyuRq\"]').click()\n",
    "            except:\n",
    "                None\n",
    "            name_review = rev.find_element(By.XPATH,'.//div[@class= \"d4r55 \"]').text\n",
    "            text_review = rev.find_element(By.XPATH,'.//div[@class= \"MyEned\"]/span').text\n",
    "            datetime_review = rev.find_element(By.XPATH,'.//span[@class= \"rsqaWe\"]').text\n",
    "            rating_review = rev.find_element(By.XPATH,'.//span[@class= \"kvMYJc\"]').get_attribute('aria-label')\n",
    "            temp['reviewer_name'].append(name_review)\n",
    "            temp['review'].append(text_review)\n",
    "            temp['date'].append(datetime_review)\n",
    "            temp['rating'].append(rating_review)\n",
    "        except :\n",
    "            None\n",
    "    df = pd.DataFrame(temp)\n",
    "    df['store'] = comp_store_name\n",
    "    df['Region'] = comp_region\n",
    "    df['Province'] = comp_province\n",
    "    df.insert(0,'competitor',conf_competitor_name)\n",
    "    df.to_sql(name=conf_sql_name,con = engine ,if_exists='append',index=False)\n",
    "    clear_output()\n",
    "    print(comp_store_name, f\"total review : {len(df)}\")\n",
    "\n",
    "def scroll_review():\n",
    "    num_reviews = 0 \n",
    "    try :\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, \"//div[contains(@class, 'm6QErb') and contains(@class, 'DxyBCb') and contains(@class, 'kA9KIf') and contains(@class, 'dS8AEf')]\"))\n",
    "            )\n",
    "        \n",
    "        body = driver.find_element(By.XPATH, \"//div[contains(@class, 'm6QErb') and contains(@class, 'DxyBCb') and contains(@class, 'kA9KIf') and contains(@class, 'dS8AEf')]\")\n",
    "        num_reviews = len(driver.find_elements(By.XPATH, '//div[contains(@class, \"jftiEf\")]'))\n",
    "        while True:\n",
    "            body.send_keys(Keys.END)\n",
    "            time.sleep(2)  # Adjust the delay based on your internet speed and page loading time\n",
    "            new_num_reviews = len(driver.find_elements(By.XPATH, '//div[contains(@class, \"jftiEf\")]'))\n",
    "            stop_date_scroll = driver.find_elements(By.XPATH,'//span[@class=\"rsqaWe\"]')[-1].text\n",
    "            if new_num_reviews == num_reviews or re.search('tahun',stop_date_scroll):\n",
    "                # Scroll to the top to ensure all reviews are loaded\n",
    "                body.send_keys(Keys.HOME)\n",
    "                WebDriverWait(driver, 5).until(\n",
    "                lambda driver: len(driver.find_elements(By.XPATH, '//div[contains(@class, \"jftiEf\")]')) > num_reviews\n",
    "                )\n",
    "                break\n",
    "            num_reviews = new_num_reviews\n",
    "    except :\n",
    "        None\n",
    "\n",
    "def get_review_store(comp_store_name,comp_link_store,comp_region,comp_province):\n",
    "    try : #Find Review (Jika tidak ada, maka continue ke next loop store)\n",
    "        driver.get(comp_link_store)\n",
    "        WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.XPATH, '//button[@class=\"hh2c6 \"][1]'))\n",
    "        )\n",
    "        button_review = driver.find_element(By.XPATH, \"//button[@class='hh2c6 '][1]\").click()\n",
    "        time.sleep(1.5)\n",
    "        WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.XPATH, '//button[@class=\"g88MCb S9kvJb \" and @data-value=\"Urutkan\"]'))\n",
    "        )\n",
    "        button_sort = driver.find_element(By.XPATH,'//button[@class=\"g88MCb S9kvJb \" and @data-value=\"Urutkan\"]').click()\n",
    "        time.sleep(1.5)\n",
    "        WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.XPATH, '//div[@class=\"fxNQSd\" and @data-index=\"1\"]'))\n",
    "        )\n",
    "        button_sort_new = driver.find_element(By.XPATH,'//div[@class=\"fxNQSd\" and @data-index=\"1\"]').click()\n",
    "        time.sleep(1.5)\n",
    "        scroll_review()\n",
    "        save_review(comp_store_name,comp_region,comp_province)\n",
    "    except:\n",
    "        return\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
    "def looping_per_store(df_store):#Main Program\n",
    "    for i in range(len(df_store)):\n",
    "        comp_link_store = df_store['Link Gmaps'][i]\n",
    "        comp_store_name = df_store['Store Name'][i]\n",
    "        comp_region = df_store['Region'][i]\n",
    "        comp_province = df_store['Province'][i]\n",
    "        if pd.isna(comp_link_store) == True:\n",
    "            continue\n",
    "        else :\n",
    "            get_review_store(comp_store_name,comp_link_store,comp_region,comp_province)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miniso Ruko Kelapa Gading 219 total review : 4\n"
     ]
    }
   ],
   "source": [
    "looping_per_store(df_store)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlowGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
